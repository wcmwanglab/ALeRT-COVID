{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code is for ModelB\n",
    "build source model based on source countries data(CCPM only) and predict CCPM for target countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T08:58:41.864823Z",
     "start_time": "2020-06-23T08:58:41.853969Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import datetime \n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.models import load_model,clone_model\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, Dense,  Lambda\n",
    "\n",
    "from keras.backend import slice\n",
    "from keras.constraints import max_norm\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='-1'\n",
    "\n",
    "##　locate the directory storing the data \n",
    "os.chdir(os.getcwd()+'/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T08:58:43.200437Z",
     "start_time": "2020-06-23T08:58:43.193301Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T08:58:43.785048Z",
     "start_time": "2020-06-23T08:58:43.778571Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_sequences_x(data, seq_length):\n",
    "    xs = []\n",
    "    for i in range(len(data)-seq_length+1):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        xs.append(x)\n",
    "\n",
    "    return np.array(xs)\n",
    "\n",
    "\n",
    "def create_sequences_y(data, seq_length):\n",
    "    ys = []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        y = data[i]\n",
    "        ys.append(y)\n",
    "    return np.array(ys)\n",
    "\n",
    "def MAPE(y, y_pred):\n",
    "    mape = sum(abs(y-y_pred)/y)/len(y)\n",
    "    print('MAPE: ', mape)\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build the source model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Construct source  sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T08:58:46.516829Z",
     "start_time": "2020-06-23T08:58:46.512025Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from re import sub\n",
    "mypath = './source/'\n",
    "source_countries=['Austria','China (except Hubei)','Croatia','Germany','Hubei','Italy','Japan',\n",
    "            'Lebanon','Monaco','Norway','Oman','United Arab Emirates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T08:58:49.787427Z",
     "start_time": "2020-06-23T08:58:47.296085Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austria\n",
      "China (except Hubei)\n",
      "Croatia\n",
      "Germany\n",
      "Hubei\n",
      "Italy\n",
      "Japan\n",
      "Lebanon\n",
      "Monaco\n",
      "Norway\n",
      "Oman\n",
      "United Arab Emirates\n"
     ]
    }
   ],
   "source": [
    "pred_length = 7\n",
    "seq_length = 7\n",
    "x_seq0 = []\n",
    "y_seq0 = []\n",
    "\n",
    "for sc in source_countries:\n",
    "    print(sc)\n",
    "    # data preprocessing\n",
    "    df = pd.read_excel('source/'+sc+'.xlsx', index_col=0)\n",
    "\n",
    "    df_new_1day = df[['confirmed cases per million']].diff(periods=1)\n",
    "    df_new_1day.rename(columns={'confirmed cases per million':'new cases'}, inplace=True)\n",
    "\n",
    "    df_new_7days = df[['confirmed cases per million']].diff(periods=pred_length)\n",
    "    df_new_7days.rename(columns={'confirmed cases per million':'new cases'}, inplace=True)\n",
    "\n",
    "    df_new_7days['cum cases'] = 0\n",
    "    df_new_7days['cum cases'][pred_length:] = df['confirmed cases per million'].values[0:len(df_new_7days)-pred_length]\n",
    "    \n",
    "    scaler_x = MinMaxScaler() #scale data into 0-1\n",
    "    scaler_y = MinMaxScaler()\n",
    "\n",
    "    if len(x_seq0)==0:\n",
    "        x_seq0 = create_sequences_x(np.array(df_new_1day.dropna()), seq_length)\n",
    "        y_seq0 = create_sequences_y(np.array(df_new_7days.dropna()), seq_length)\n",
    "        x_seq0 = x_seq0[0:len(y_seq0)]\n",
    "    else:\n",
    "        tx_seq0 = create_sequences_x(np.array(df_new_1day.dropna()), seq_length)\n",
    "        ty_seq0 = create_sequences_y(np.array(df_new_7days.dropna()), seq_length)\n",
    "        tx_seq0 = tx_seq0[0:len(ty_seq0)]\n",
    "        \n",
    "        x_seq0 = np.concatenate((x_seq0, tx_seq0),axis=0)\n",
    "        y_seq0 = np.concatenate((y_seq0, ty_seq0),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 scale the sequence values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T08:58:50.589496Z",
     "start_time": "2020-06-23T08:58:50.582350Z"
    }
   },
   "outputs": [],
   "source": [
    "x_seq1 = np.reshape(x_seq0, newshape=(-1,1))\n",
    "\n",
    "scaler_x = scaler_x.fit(x_seq1)\n",
    "x = scaler_x.transform(x_seq1)\n",
    "x = np.reshape(x, newshape=(x_seq0.shape))\n",
    "y_seq1 = np.reshape(y_seq0[:,0:1], newshape=(-1,1))\n",
    "\n",
    "scaler_y = scaler_y.fit(y_seq1)\n",
    "y = scaler_y.transform(y_seq1)\n",
    "\n",
    "y = np.reshape(y, newshape=(y_seq0[:,0:1].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.3 source model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T09:04:28.059695Z",
     "start_time": "2020-06-23T09:04:23.853637Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data1/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /data1/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/9\n",
      "714/714 [==============================] - 1s 1ms/step - loss: 0.0226\n",
      "Epoch 2/9\n",
      "714/714 [==============================] - 0s 336us/step - loss: 0.0180\n",
      "Epoch 3/9\n",
      "714/714 [==============================] - 0s 355us/step - loss: 0.0163\n",
      "Epoch 4/9\n",
      "714/714 [==============================] - 0s 346us/step - loss: 0.0147\n",
      "Epoch 5/9\n",
      "714/714 [==============================] - 0s 346us/step - loss: 0.0134\n",
      "Epoch 6/9\n",
      "714/714 [==============================] - 0s 350us/step - loss: 0.0129\n",
      "Epoch 7/9\n",
      "714/714 [==============================] - 0s 339us/step - loss: 0.0122\n",
      "Epoch 8/9\n",
      "714/714 [==============================] - 0s 359us/step - loss: 0.0121\n",
      "Epoch 9/9\n",
      "714/714 [==============================] - 0s 342us/step - loss: 0.0119\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from random import sample\n",
    "random.seed(123)\n",
    "train_idx = sample(range(len(x)),int(len(x)*0.8))\n",
    "test_idx = set(range(len(x))).difference(train_idx)\n",
    "\n",
    "\n",
    "X_train = x[train_idx].copy()\n",
    "y_train = np.reshape(y[train_idx], (-1))\n",
    "\n",
    "X_test = x[list(test_idx)].copy()\n",
    "y_test = np.reshape(y[list(test_idx)], (-1))\n",
    "\n",
    "# Building the RNN\n",
    "\n",
    "main_input = Input(shape=(seq_length,1,), dtype='float32', name='main_input')  \n",
    "\n",
    "lstm_out = LSTM(4)(main_input)  \n",
    "main_output = Dense(units = 1)(lstm_out)\n",
    "regressor = Model(inputs=main_input, outputs=main_output)\n",
    "\n",
    "regressor.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 9, batch_size = 16)#  10\n",
    "regressor.save('../model/ModelB_nocontrol.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Target countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T09:04:50.992860Z",
     "start_time": "2020-06-23T09:04:50.987365Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from re import sub\n",
    "mypath = 'target/'\n",
    "# target_countries = ['Albania','Algeria','Argentina','Armenia','Australia','Azerbaijan','Bangladesh','Belarus','Belgium','Bermuda',\n",
    "#              'Bolivia','Brazil','Bulgaria','Canada','Chile','Colombia','Costa Rica','Cuba','Czech Republic','Denmark',\n",
    "#              'El Salvador','Estonia','Finland','France','Ghana','Gibraltar','Greece','Honduras','Hungary','India',\n",
    "#              'Indonesia','Iran','Iraq','Ireland','Israel','Jamaica','Jordan','Liberia','Luxembourg','Malaysia','Mexico',\n",
    "#              'Morocco','Nepal','Netherlands','Nigeria','Pakistan','Paraguay','Peru','Philippines','Poland','Portugal',\n",
    "#              'Qatar','Republic of the Congo','Romania','Russia','Rwanda','Saudi Arabia','Senegal','Sierra Leone',\n",
    "#              'Singapore','Slovakia','Slovenia','South Africa','Sri Lanka','Switzerland','Thailand','Tunisia','Turkey',\n",
    "#              'Ukraine','United Kingdom','United States','Venezuela']\n",
    "\n",
    "target_countries = ['Australia','France','Greece','Iraq','Netherlands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T09:04:53.227058Z",
     "start_time": "2020-06-23T09:04:51.615955Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_model = load_model('../model/ModelB_nocontrol.pkl')\n",
    "ret_test = pd.DataFrame(index=target_countries, columns=['MAPE'])\n",
    "no_control = pd.DataFrame(index=['loop1','loop2','loop3','loop4','loop5'], columns=['MAPE(mean)','MAPE(std)','MAPE<0.1','MAPE<0.05'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T09:06:50.347261Z",
     "start_time": "2020-06-23T09:06:22.047509Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia\n",
      "MAPE:  0.045807415471918696\n",
      "France\n",
      "MAPE:  0.026227821083216512\n",
      "Greece\n",
      "MAPE:  0.03944255519134048\n",
      "Iraq\n",
      "MAPE:  0.10229714895687346\n",
      "Netherlands\n",
      "MAPE:  0.033947424745118235\n"
     ]
    }
   ],
   "source": [
    "for l in range(1):\n",
    "    for tar in target_countries:\n",
    "        print(tar)\n",
    "        # data preprocessing\n",
    "\n",
    "        ## scale data\n",
    "        df = pd.read_excel('target/'+tar+'.xlsx', index_col=0)\n",
    "\n",
    "        df_new_1day = df.diff(periods=1)\n",
    "        df_new_1day.rename(columns={'confirmed cases per million':'new cases'}, inplace=True)\n",
    "\n",
    "        df_new_7days = df[['confirmed cases per million']].diff(periods=pred_length)\n",
    "        df_new_7days.rename(columns={'confirmed cases per million':'new cases'}, inplace=True)\n",
    "\n",
    "        df_new_7days['cum cases'] = 0\n",
    "        df_new_7days['cum cases'][pred_length:] = df['confirmed cases per million'].values[0:len(df_new_7days)-pred_length]\n",
    "\n",
    "        x_seq0 = create_sequences_x(np.array(df_new_1day.dropna()), seq_length)\n",
    "        y_seq0 = create_sequences_y(np.array(df_new_7days.dropna()), seq_length)\n",
    "        x_seq0 = x_seq0[0:len(y_seq0)]\n",
    "        x_seq1 = np.reshape(x_seq0, newshape=(-1,1))\n",
    "\n",
    "        x = scaler_x.transform(x_seq1)\n",
    "\n",
    "        x = np.reshape(x, newshape=(x_seq0.shape))\n",
    "        y_seq1 = np.reshape(y_seq0[:,0:1], newshape=(-1,1))\n",
    "        y = scaler_y.transform(y_seq1)\n",
    "\n",
    "        y = np.reshape(y, newshape=(y_seq0[:,0:1].shape))\n",
    "        model =clone_model(pred_model)\n",
    "        model.set_weights(pred_model.get_weights())\n",
    "        test_idx = int(len(x)*0.8)\n",
    "\n",
    "        X_train = x[0:test_idx, :, 0:1].copy()\n",
    "        y_train = np.reshape(y[0:test_idx], (-1))\n",
    "\n",
    "        X_test = x[test_idx:,:,0:1].copy()\n",
    "        y_test = np.reshape(y[test_idx:], (-1))\n",
    "\n",
    "\n",
    "        for layer in model.layers[:-1]:\n",
    "            layer.trainable=False\n",
    "        for layer in model.layers[-1:]:\n",
    "            layer.trainable=True\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        # Fitting the RNN to the Training set\n",
    "        model.fit(X_train, y_train, epochs = 7, batch_size = 4, verbose=0)# 原来10\n",
    "\n",
    "        # Predicting daily cases\n",
    "        predicted_cases = model.predict(X_test)\n",
    "        predicted_cases = scaler_y.inverse_transform(predicted_cases)\n",
    "\n",
    "        true_cases = np.reshape(scaler_y.inverse_transform(np.reshape(y_test,(-1,1))),(-1))+y_seq0[test_idx:,1]\n",
    "        predicted_cases = np.reshape(predicted_cases,(-1))+y_seq0[test_idx:,1]\n",
    "\n",
    "        mape = MAPE(true_cases, predicted_cases)\n",
    "        ret_test.loc[tar, 'MAPE'] = mape\n",
    "        \n",
    "    no_control.loc['loop'+str(l+1), 'MAPE(mean)'] = ret_test.MAPE.mean() \n",
    "    no_control.loc['loop'+str(l+1), 'MAPE(std)'] = ret_test.MAPE.std()\n",
    "    no_control.loc['loop'+str(l+1), 'MAPE<0.1'] = ret_test[(ret_test.MAPE<0.1)].shape[0]\n",
    "    no_control.loc['loop'+str(l+1), 'MAPE<0.05']=ret_test[(ret_test.MAPE<0.05)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:42:31.968943Z",
     "start_time": "2020-06-19T08:42:31.952780Z"
    }
   },
   "outputs": [],
   "source": [
    "no_control.to_csv('../result/ModelB_nocontrol.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
