{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T07:38:19.481334Z",
     "start_time": "2020-06-05T07:38:16.366759Z"
    }
   },
   "source": [
    "# The code is used to build the pre_train model for the source countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T08:42:22.694817Z",
     "start_time": "2020-06-23T08:42:19.260318Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import time \n",
    "import keras \n",
    "import sys\n",
    "import random\n",
    "\n",
    "\n",
    "from keras.layers import multiply\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import *\n",
    "import keras.backend as K\n",
    "from keras.layers import Concatenate\n",
    "from keras.constraints import max_norm\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "os.getcwd()\n",
    "seed=666\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T08:42:37.310360Z",
     "start_time": "2020-06-23T08:42:37.304881Z"
    }
   },
   "outputs": [],
   "source": [
    "#create the sequence slice for the model\n",
    "def create_sequences(data, seq_length, next_days):\n",
    "\n",
    "    N=len(data)-seq_length-next_days+1\n",
    "    xs = np.zeros((N,seq_length,1))   \n",
    "    ys = np.zeros((N,1))\n",
    "    cs = np.zeros((N,seq_length,1))\n",
    "    \n",
    "    for i in range(N):\n",
    "        xs[i,:,0] = data[i:i+seq_length,0]\n",
    "        ys[i] = data[i+seq_length:i+seq_length+next_days,0].sum() \n",
    "        cs[i,:,0] = data[i:i+seq_length,1]\n",
    "    return xs,ys,cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T08:42:39.003534Z",
     "start_time": "2020-06-23T08:42:38.993172Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_attention_applied_after_lstm(x_input,c_input,y_input):\n",
    "    INPUT_DIM =1\n",
    "    TIME_STEPS=7\n",
    "    lstm_units = 32\n",
    "\n",
    "    inputs1 = Input(shape=(TIME_STEPS, INPUT_DIM,))\n",
    "    inputs2 = Input(shape=(TIME_STEPS,))  \n",
    "    lstm_out = LSTM(lstm_units, return_sequences=True)(inputs1)\n",
    "\n",
    "    a = Permute((2, 1))(lstm_out)\n",
    "    a = Reshape((lstm_units, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "    a = RepeatVector(INPUT_DIM)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    output_attention_mul = multiply([lstm_out, a_probs])\n",
    "    attention_mul = Flatten()(output_attention_mul) \n",
    "    newcase_output = Dense(16)(attention_mul)        \n",
    "    newcase_output = Dense(1,activation='sigmoid')(newcase_output)\n",
    "\n",
    "   #add the weight to the lockdown measures according to the domain knowledge\n",
    "    def control_rate(x,rate=0.1):\n",
    "        rate2= rate*K.ones((7,1))\n",
    "        return  K.dot(x,rate2)\n",
    "\n",
    "    inputs1_new = Flatten()(inputs1)    \n",
    "    inputs2_new = multiply([inputs2, inputs1_new])\n",
    "    control_output=Lambda(control_rate)(inputs2_new) \n",
    "   \n",
    "    output=keras.layers.Add()([newcase_output,control_output])\n",
    "\n",
    "\n",
    "    model = Model(input=[inputs1 ,inputs2], output=output)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit([x_input,c_input], y_input, epochs=100, batch_size=32,  \n",
    "              validation_data=([x_input,c_input],y_input))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T03:03:06.396031Z",
     "start_time": "2020-06-23T03:02:07.395075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data1/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ad...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data1/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 903 samples, validate on 903 samples\n",
      "Epoch 1/100\n",
      "903/903 [==============================] - 2s 2ms/step - loss: 0.1335 - val_loss: 0.1060\n",
      "Epoch 2/100\n",
      "903/903 [==============================] - 1s 579us/step - loss: 0.0802 - val_loss: 0.0717\n",
      "Epoch 3/100\n",
      "903/903 [==============================] - 1s 572us/step - loss: 0.0668 - val_loss: 0.0625\n",
      "Epoch 4/100\n",
      "903/903 [==============================] - 1s 576us/step - loss: 0.0598 - val_loss: 0.0567\n",
      "Epoch 5/100\n",
      "903/903 [==============================] - 1s 568us/step - loss: 0.0547 - val_loss: 0.0534\n",
      "Epoch 6/100\n",
      "903/903 [==============================] - 1s 560us/step - loss: 0.0525 - val_loss: 0.0517\n",
      "Epoch 7/100\n",
      "903/903 [==============================] - 1s 567us/step - loss: 0.0516 - val_loss: 0.0507\n",
      "Epoch 8/100\n",
      "903/903 [==============================] - 1s 569us/step - loss: 0.0504 - val_loss: 0.0505\n",
      "Epoch 9/100\n",
      "903/903 [==============================] - 1s 570us/step - loss: 0.0499 - val_loss: 0.0490\n",
      "Epoch 10/100\n",
      "903/903 [==============================] - 1s 561us/step - loss: 0.0491 - val_loss: 0.0485\n",
      "Epoch 11/100\n",
      "903/903 [==============================] - 1s 580us/step - loss: 0.0484 - val_loss: 0.0475\n",
      "Epoch 12/100\n",
      "903/903 [==============================] - 1s 570us/step - loss: 0.0473 - val_loss: 0.0469\n",
      "Epoch 13/100\n",
      "903/903 [==============================] - 1s 561us/step - loss: 0.0467 - val_loss: 0.0462\n",
      "Epoch 14/100\n",
      "903/903 [==============================] - 1s 558us/step - loss: 0.0459 - val_loss: 0.0456\n",
      "Epoch 15/100\n",
      "903/903 [==============================] - 1s 574us/step - loss: 0.0452 - val_loss: 0.0460\n",
      "Epoch 16/100\n",
      "903/903 [==============================] - 1s 567us/step - loss: 0.0446 - val_loss: 0.0442\n",
      "Epoch 17/100\n",
      "903/903 [==============================] - 1s 570us/step - loss: 0.0441 - val_loss: 0.0441\n",
      "Epoch 18/100\n",
      "903/903 [==============================] - 1s 580us/step - loss: 0.0434 - val_loss: 0.0432\n",
      "Epoch 19/100\n",
      "903/903 [==============================] - 1s 580us/step - loss: 0.0431 - val_loss: 0.0424\n",
      "Epoch 20/100\n",
      "903/903 [==============================] - 1s 576us/step - loss: 0.0427 - val_loss: 0.0420\n",
      "Epoch 21/100\n",
      "903/903 [==============================] - 1s 577us/step - loss: 0.0422 - val_loss: 0.0424\n",
      "Epoch 22/100\n",
      "903/903 [==============================] - 1s 584us/step - loss: 0.0421 - val_loss: 0.0406\n",
      "Epoch 23/100\n",
      "903/903 [==============================] - 1s 574us/step - loss: 0.0417 - val_loss: 0.0406\n",
      "Epoch 24/100\n",
      "903/903 [==============================] - 1s 580us/step - loss: 0.0408 - val_loss: 0.0402\n",
      "Epoch 25/100\n",
      "903/903 [==============================] - 1s 561us/step - loss: 0.0400 - val_loss: 0.0394\n",
      "Epoch 26/100\n",
      "903/903 [==============================] - 0s 550us/step - loss: 0.0390 - val_loss: 0.0387\n",
      "Epoch 27/100\n",
      "903/903 [==============================] - 0s 553us/step - loss: 0.0389 - val_loss: 0.0384\n",
      "Epoch 28/100\n",
      "903/903 [==============================] - 0s 542us/step - loss: 0.0382 - val_loss: 0.0381\n",
      "Epoch 29/100\n",
      "903/903 [==============================] - 0s 545us/step - loss: 0.0386 - val_loss: 0.0378\n",
      "Epoch 30/100\n",
      "903/903 [==============================] - 0s 537us/step - loss: 0.0390 - val_loss: 0.0391\n",
      "Epoch 31/100\n",
      "903/903 [==============================] - 0s 532us/step - loss: 0.0385 - val_loss: 0.0369\n",
      "Epoch 32/100\n",
      "903/903 [==============================] - 0s 546us/step - loss: 0.0371 - val_loss: 0.0366\n",
      "Epoch 33/100\n",
      "903/903 [==============================] - 0s 535us/step - loss: 0.0371 - val_loss: 0.0365\n",
      "Epoch 34/100\n",
      "903/903 [==============================] - 0s 539us/step - loss: 0.0370 - val_loss: 0.0364\n",
      "Epoch 35/100\n",
      "903/903 [==============================] - 0s 534us/step - loss: 0.0372 - val_loss: 0.0361\n",
      "Epoch 36/100\n",
      "903/903 [==============================] - 0s 538us/step - loss: 0.0366 - val_loss: 0.0384\n",
      "Epoch 37/100\n",
      "903/903 [==============================] - 1s 573us/step - loss: 0.0382 - val_loss: 0.0360\n",
      "Epoch 38/100\n",
      "903/903 [==============================] - 1s 575us/step - loss: 0.0395 - val_loss: 0.0370\n",
      "Epoch 39/100\n",
      "903/903 [==============================] - 1s 569us/step - loss: 0.0367 - val_loss: 0.0362\n",
      "Epoch 40/100\n",
      "903/903 [==============================] - 1s 559us/step - loss: 0.0364 - val_loss: 0.0375\n",
      "Epoch 41/100\n",
      "903/903 [==============================] - 0s 552us/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 42/100\n",
      "903/903 [==============================] - 0s 545us/step - loss: 0.0362 - val_loss: 0.0356\n",
      "Epoch 43/100\n",
      "903/903 [==============================] - 0s 552us/step - loss: 0.0375 - val_loss: 0.0364\n",
      "Epoch 44/100\n",
      "903/903 [==============================] - 1s 564us/step - loss: 0.0377 - val_loss: 0.0358\n",
      "Epoch 45/100\n",
      "903/903 [==============================] - 1s 562us/step - loss: 0.0363 - val_loss: 0.0356\n",
      "Epoch 46/100\n",
      "903/903 [==============================] - 1s 557us/step - loss: 0.0357 - val_loss: 0.0357\n",
      "Epoch 47/100\n",
      "903/903 [==============================] - 1s 566us/step - loss: 0.0356 - val_loss: 0.0353\n",
      "Epoch 48/100\n",
      "903/903 [==============================] - 1s 568us/step - loss: 0.0359 - val_loss: 0.0352\n",
      "Epoch 49/100\n",
      "903/903 [==============================] - 1s 573us/step - loss: 0.0360 - val_loss: 0.0354\n",
      "Epoch 50/100\n",
      "903/903 [==============================] - 1s 569us/step - loss: 0.0359 - val_loss: 0.0355\n",
      "Epoch 51/100\n",
      "903/903 [==============================] - 1s 575us/step - loss: 0.0355 - val_loss: 0.0358\n",
      "Epoch 52/100\n",
      "903/903 [==============================] - 1s 576us/step - loss: 0.0353 - val_loss: 0.0350\n",
      "Epoch 53/100\n",
      "903/903 [==============================] - 1s 582us/step - loss: 0.0361 - val_loss: 0.0352\n",
      "Epoch 54/100\n",
      "903/903 [==============================] - 1s 606us/step - loss: 0.0352 - val_loss: 0.0354\n",
      "Epoch 55/100\n",
      "903/903 [==============================] - 1s 577us/step - loss: 0.0354 - val_loss: 0.0350\n",
      "Epoch 56/100\n",
      "903/903 [==============================] - 1s 627us/step - loss: 0.0351 - val_loss: 0.0349\n",
      "Epoch 57/100\n",
      "903/903 [==============================] - 1s 611us/step - loss: 0.0356 - val_loss: 0.0348\n",
      "Epoch 58/100\n",
      "903/903 [==============================] - 1s 634us/step - loss: 0.0355 - val_loss: 0.0350\n",
      "Epoch 59/100\n",
      "903/903 [==============================] - 1s 646us/step - loss: 0.0354 - val_loss: 0.0348\n",
      "Epoch 60/100\n",
      "903/903 [==============================] - 1s 618us/step - loss: 0.0350 - val_loss: 0.0346\n",
      "Epoch 61/100\n",
      "903/903 [==============================] - 1s 598us/step - loss: 0.0346 - val_loss: 0.0357\n",
      "Epoch 62/100\n",
      "903/903 [==============================] - 1s 601us/step - loss: 0.0353 - val_loss: 0.0353\n",
      "Epoch 63/100\n",
      "903/903 [==============================] - 1s 606us/step - loss: 0.0361 - val_loss: 0.0357\n",
      "Epoch 64/100\n",
      "903/903 [==============================] - 1s 560us/step - loss: 0.0350 - val_loss: 0.0348\n",
      "Epoch 65/100\n",
      "903/903 [==============================] - 1s 558us/step - loss: 0.0351 - val_loss: 0.0359\n",
      "Epoch 66/100\n",
      "903/903 [==============================] - 1s 568us/step - loss: 0.0355 - val_loss: 0.0346\n",
      "Epoch 67/100\n",
      "903/903 [==============================] - 1s 583us/step - loss: 0.0351 - val_loss: 0.0368\n",
      "Epoch 68/100\n",
      "903/903 [==============================] - 1s 589us/step - loss: 0.0351 - val_loss: 0.0344\n",
      "Epoch 69/100\n",
      "903/903 [==============================] - 1s 581us/step - loss: 0.0351 - val_loss: 0.0354\n",
      "Epoch 70/100\n",
      "903/903 [==============================] - 1s 574us/step - loss: 0.0355 - val_loss: 0.0347\n",
      "Epoch 71/100\n",
      "903/903 [==============================] - 1s 587us/step - loss: 0.0348 - val_loss: 0.0345\n",
      "Epoch 72/100\n",
      "903/903 [==============================] - 1s 579us/step - loss: 0.0346 - val_loss: 0.0347\n",
      "Epoch 73/100\n",
      "903/903 [==============================] - 1s 576us/step - loss: 0.0351 - val_loss: 0.0343\n",
      "Epoch 74/100\n",
      "903/903 [==============================] - 1s 570us/step - loss: 0.0354 - val_loss: 0.0342\n",
      "Epoch 75/100\n",
      "903/903 [==============================] - 1s 571us/step - loss: 0.0345 - val_loss: 0.0343\n",
      "Epoch 76/100\n",
      "903/903 [==============================] - 1s 579us/step - loss: 0.0347 - val_loss: 0.0341\n",
      "Epoch 77/100\n",
      "903/903 [==============================] - 1s 580us/step - loss: 0.0345 - val_loss: 0.0351\n",
      "Epoch 78/100\n",
      "903/903 [==============================] - 1s 579us/step - loss: 0.0350 - val_loss: 0.0343\n",
      "Epoch 79/100\n",
      "903/903 [==============================] - 1s 593us/step - loss: 0.0347 - val_loss: 0.0343\n",
      "Epoch 80/100\n",
      "903/903 [==============================] - 1s 578us/step - loss: 0.0352 - val_loss: 0.0342\n",
      "Epoch 81/100\n",
      "903/903 [==============================] - 1s 585us/step - loss: 0.0346 - val_loss: 0.0341\n",
      "Epoch 82/100\n",
      "903/903 [==============================] - 1s 576us/step - loss: 0.0346 - val_loss: 0.0340\n",
      "Epoch 83/100\n",
      "903/903 [==============================] - 1s 576us/step - loss: 0.0351 - val_loss: 0.0341\n",
      "Epoch 84/100\n",
      "903/903 [==============================] - 1s 602us/step - loss: 0.0341 - val_loss: 0.0342\n",
      "Epoch 85/100\n",
      "903/903 [==============================] - 1s 571us/step - loss: 0.0343 - val_loss: 0.0343\n",
      "Epoch 86/100\n",
      "903/903 [==============================] - 1s 557us/step - loss: 0.0343 - val_loss: 0.0341\n",
      "Epoch 87/100\n",
      "903/903 [==============================] - 1s 570us/step - loss: 0.0345 - val_loss: 0.0338\n",
      "Epoch 88/100\n",
      "903/903 [==============================] - 1s 570us/step - loss: 0.0343 - val_loss: 0.0338\n",
      "Epoch 89/100\n",
      "903/903 [==============================] - 1s 580us/step - loss: 0.0342 - val_loss: 0.0338\n",
      "Epoch 90/100\n",
      "903/903 [==============================] - 1s 569us/step - loss: 0.0343 - val_loss: 0.0338\n",
      "Epoch 91/100\n",
      "903/903 [==============================] - 1s 567us/step - loss: 0.0340 - val_loss: 0.0336\n",
      "Epoch 92/100\n",
      "903/903 [==============================] - 1s 583us/step - loss: 0.0339 - val_loss: 0.0352\n",
      "Epoch 93/100\n",
      "903/903 [==============================] - 1s 560us/step - loss: 0.0353 - val_loss: 0.0345\n",
      "Epoch 94/100\n",
      "903/903 [==============================] - 1s 580us/step - loss: 0.0339 - val_loss: 0.0336\n",
      "Epoch 95/100\n",
      "903/903 [==============================] - 1s 579us/step - loss: 0.0340 - val_loss: 0.0336\n",
      "Epoch 96/100\n",
      "903/903 [==============================] - 1s 590us/step - loss: 0.0338 - val_loss: 0.0337\n",
      "Epoch 97/100\n",
      "903/903 [==============================] - 1s 560us/step - loss: 0.0341 - val_loss: 0.0336\n",
      "Epoch 98/100\n",
      "903/903 [==============================] - 1s 571us/step - loss: 0.0338 - val_loss: 0.0340\n",
      "Epoch 99/100\n",
      "903/903 [==============================] - 1s 607us/step - loss: 0.0347 - val_loss: 0.0353\n",
      "Epoch 100/100\n",
      "903/903 [==============================] - 1s 620us/step - loss: 0.0341 - val_loss: 0.0335\n"
     ]
    }
   ],
   "source": [
    "#list the source countries\n",
    "source_countries=['Austria','China (except Hubei)','Croatia','Germany','Hubei','Italy','Japan',\n",
    "            'Lebanon','Monaco','Norway','Oman','United Arab Emirates']\n",
    "\n",
    "seq_length=7\n",
    "next_days=7\n",
    "\n",
    "x_train_total=np.zeros((0,seq_length,1))\n",
    "c_train_total=np.zeros((0,seq_length))\n",
    "y_train_total=np.zeros((0,1))\n",
    "\n",
    "INPUT_DIM = 2\n",
    "TIME_STEPS = 7\n",
    "\n",
    "for i in range(len(source_countries)):\n",
    "    #load the data \n",
    "    country_name='./data/source/'+source_countries[i]+'.xlsx'\n",
    "    data_dist =  pd.read_excel(country_name,encoding='gbk').dropna()\n",
    "    data_dist=data_dist.drop(['截止时间'],axis=1)\n",
    "    data_diff= data_dist['confirmed cases per million'].diff().dropna()\n",
    "    data_diff=pd.concat([data_diff,data_dist.iloc[1:,1]],axis=1)\n",
    "    data_diff=np.array( data_diff)\n",
    "    \n",
    "    x,y,c=create_sequences(data_diff, seq_length, next_days)\n",
    "    \n",
    "    #normalization\n",
    "    x_max=x.max()\n",
    "    x_min=x.min()\n",
    "    x=(x-x_min)/(x_max-x_min)\n",
    "    \n",
    "    y_max=y.max()\n",
    "    y_min=y.min()\n",
    "    y=(y-y_min)/(y_max-y_min)\n",
    "\n",
    "    # concat all the countries samples to train a source model\n",
    "    c=np.ones((c.shape[0],c.shape[1]))-c.reshape(-1,seq_length)\n",
    "    \n",
    "    x_train=x.reshape(-1,seq_length,1)\n",
    "    c_train=c.reshape(-1,seq_length)\n",
    "    y_train=y.reshape(-1,1)    \n",
    "    \n",
    "    x_train_total=np.concatenate((x_train_total,x_train),axis=0)\n",
    "    c_train_total=np.concatenate((c_train_total,c_train),axis=0)    \n",
    "    y_train_total=np.concatenate((y_train_total,y_train),axis=0)    \n",
    "\n",
    "model = model_attention_applied_after_lstm(x_train_total,c_train_total,y_train_total)\n",
    "#save the model\n",
    "model.save('./model/source_model_ALerT-COVID.pkl')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code is used to verify the effect of ALerT-COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T08:53:14.936841Z",
     "start_time": "2020-06-23T08:51:25.491194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Australia\n",
      "1 France\n",
      "2 Greece\n",
      "3 Iraq\n",
      "4 Netherlands\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mape</th>\n",
       "      <th>true_data</th>\n",
       "      <th>pred_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>0.023682</td>\n",
       "      <td>282.040499</td>\n",
       "      <td>288.921578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>0.016752</td>\n",
       "      <td>2889.763353</td>\n",
       "      <td>2910.115905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greece</th>\n",
       "      <td>0.028023</td>\n",
       "      <td>279.668512</td>\n",
       "      <td>288.088274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iraq</th>\n",
       "      <td>0.078635</td>\n",
       "      <td>153.620513</td>\n",
       "      <td>134.100555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>0.023425</td>\n",
       "      <td>2699.582466</td>\n",
       "      <td>2803.307724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mape    true_data    pred_data\n",
       "Australia    0.023682   282.040499   288.921578\n",
       "France       0.016752  2889.763353  2910.115905\n",
       "Greece       0.028023   279.668512   288.088274\n",
       "Iraq         0.078635   153.620513   134.100555\n",
       "Netherlands  0.023425  2699.582466  2803.307724"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the name of target countries\n",
    "# target_cols=['Albania','Algeria','Argentina','Armenia','Australia','Azerbaijan','Bangladesh','Belarus','Belgium','Bermuda',\n",
    "#              'Bolivia','Brazil','Bulgaria','Canada','Chile','Colombia','Costa Rica','Cuba','Czech Republic','Denmark',\n",
    "#              'El Salvador','Estonia','Finland','France','Ghana','Gibraltar','Greece','Honduras','Hungary','India',\n",
    "#              'Indonesia','Iran','Iraq','Ireland','Israel','Jamaica','Jordan','Liberia','Luxembourg','Malaysia','Mexico',\n",
    "#              'Morocco','Nepal','Netherlands','Nigeria','Pakistan','Paraguay','Peru','Philippines','Poland','Portugal',\n",
    "#              'Qatar','Republic of the Congo','Romania','Russia','Rwanda','Saudi Arabia','Senegal','Sierra Leone',\n",
    "#              'Singapore','Slovakia','Slovenia','South Africa','Sri Lanka','Switzerland','Thailand','Tunisia','Turkey',\n",
    "#              'Ukraine','United Kingdom','United States','Venezuela']\n",
    "\n",
    "target_cols=['Australia','France','Greece','Iraq','Netherlands']\n",
    "\n",
    "#set the parameter\n",
    "seq_length=7\n",
    "next_days=7\n",
    "\n",
    "\n",
    "pred_total=[]\n",
    "true_data_total=[]\n",
    "pred_data_total=[]\n",
    "new_case_mape_total=[]\n",
    "cumulative_case_mape_total=[]\n",
    "\n",
    "for i in range(len(target_cols)):\n",
    "    print(i,target_cols[i])\n",
    "    # load the data\n",
    "    country_name='./data/target/'+target_cols[i]+'.xlsx'\n",
    "    data_dist =  pd.read_excel(country_name,encoding='gbk').dropna()\n",
    "    data_dist=data_dist.drop(['截止时间'],axis=1)\n",
    "    data_diff= data_dist['confirmed cases per million'].diff().dropna()\n",
    "    data_diff=pd.concat([data_diff,data_dist.iloc[1:,1]],axis=1)\n",
    "    data_diff=np.array(data_diff)\n",
    "    \n",
    "    x,y,c=create_sequences(data_diff, seq_length, next_days)\n",
    "    \n",
    "    # normalization \n",
    "    c=np.ones((c.shape[0],c.shape[1]))-c.reshape(-1,seq_length)\n",
    "    x_max=x.max()\n",
    "    x_min=x.min()\n",
    "    x=(x-x_min)/(x_max-x_min)\n",
    "    \n",
    "    y_max=y.max()\n",
    "    y_min=y.min()\n",
    "    y=(y-y_min)/(y_max-y_min)\n",
    "\n",
    "    #split the target countries data, 80% of the data is used to fine tune source model,20% is used to verify the effect  \n",
    "    index1=int(len(x)*0.8)\n",
    "    \n",
    "    x_train=x[:index1].reshape(-1,seq_length,1)\n",
    "    c_train=c[:index1].reshape(-1,seq_length)\n",
    "    y_train=y[:index1].reshape(-1,1)\n",
    "\n",
    "    \n",
    "    x_val=x[index1:].reshape(-1,seq_length,1)\n",
    "    c_val=c[index1:].reshape(-1,seq_length)\n",
    "    y_val=y[index1:].reshape(-1,1)\n",
    "    \n",
    "    #load the source model and fine_tune the model   \n",
    "    source_model='./model/source_model_ALerT-COVID.pkl'  \n",
    "    pre_model= load_model(source_model) \n",
    "    \n",
    "    for layer in pre_model.layers[:len(pre_model.layers)-2]:\n",
    "        layer.trainable = False \n",
    "        \n",
    "    pre_model.compile(loss='mse', optimizer=Adam(lr=1e-3))   \n",
    "    pre_model.fit([x_train,c_train], y_train,epochs=15, batch_size=4,\n",
    "                  validation_data=([x_val,c_val],y_val),verbose = 0)\n",
    " \n",
    "\n",
    "    pred_val = pre_model.predict([x_val,c_val])[-1,0]\n",
    "    pred_val = np.array(pred_val)*(y_max-y_min)+y_min \n",
    "    pred_val = np.array(data_dist.iloc[-8,0])+pred_val\n",
    "    \n",
    "    \n",
    "    true_val = y_val[-1,0]\n",
    "    true_val = np.array(true_val)*(y_max-y_min)+y_min \n",
    "    true_val = np.array(data_dist.iloc[-8,0])+true_val\n",
    "   \n",
    "    \n",
    "    true_data_total.append(true_val)\n",
    "    pred_data_total.append(pred_val)   \n",
    "    \n",
    "    ##  calculate the mape for new confirmed cases\n",
    "    pred_test= pre_model.predict([x_val,c_val])   \n",
    "    true_test=y_val*(y_max-y_min)+y_min \n",
    "    pred_test=pred_test*(y_max-y_min)+y_min\n",
    "    new_case_mape=np.mean(abs((pred_test-true_test)/true_test))\n",
    "    new_case_mape_total.append(new_case_mape)\n",
    "    \n",
    "    ## calculate the mape for the culmulative confirmed cases    \n",
    "    true_test_raw=np.array(data_dist.iloc[index1+7:-7,0]).reshape(-1,1)+ true_test\n",
    "    pred_test_raw=np.array(data_dist.iloc[index1+7:-7,0]).reshape(-1,1)+pred_test\n",
    "    cumulative_case_mape=np.mean(abs((pred_test_raw-true_test_raw)/true_test_raw))\n",
    "    cumulative_case_mape_total.append(cumulative_case_mape)\n",
    "\n",
    "#save the result \n",
    "result                          = pd.DataFrame(cumulative_case_mape_total,index=target_cols,columns=['mape'])\n",
    "result['true_data']             = true_data_total\n",
    "result['pred_data']             = pred_data_total\n",
    "# result.to_excel('result_verify.xls')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code is used to predict the CCPM for the next seven days in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T09:22:58.070040Z",
     "start_time": "2020-06-23T09:20:29.170586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Australia\n",
      "1 France\n",
      "2 Greece\n",
      "3 Iraq\n",
      "4 Netherlands\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre14_data</th>\n",
       "      <th>pre7_data</th>\n",
       "      <th>pred_control</th>\n",
       "      <th>pred_nocontrol</th>\n",
       "      <th>pred_true</th>\n",
       "      <th>nocontrol_control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>2.745111</td>\n",
       "      <td>3.058837</td>\n",
       "      <td>10.263621</td>\n",
       "      <td>11.233669</td>\n",
       "      <td>11.233669</td>\n",
       "      <td>0.094513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>47.553747</td>\n",
       "      <td>94.310845</td>\n",
       "      <td>274.141876</td>\n",
       "      <td>304.985199</td>\n",
       "      <td>304.985199</td>\n",
       "      <td>0.112509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greece</th>\n",
       "      <td>5.468647</td>\n",
       "      <td>3.741706</td>\n",
       "      <td>9.404870</td>\n",
       "      <td>10.512584</td>\n",
       "      <td>10.512584</td>\n",
       "      <td>0.117781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iraq</th>\n",
       "      <td>25.160052</td>\n",
       "      <td>47.411283</td>\n",
       "      <td>23.626308</td>\n",
       "      <td>51.411167</td>\n",
       "      <td>23.626308</td>\n",
       "      <td>1.176014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>69.682458</td>\n",
       "      <td>69.624098</td>\n",
       "      <td>126.926270</td>\n",
       "      <td>149.290207</td>\n",
       "      <td>142.147995</td>\n",
       "      <td>0.176196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pre14_data  pre7_data  pred_control  pred_nocontrol   pred_true  \\\n",
       "Australia      2.745111   3.058837     10.263621       11.233669   11.233669   \n",
       "France        47.553747  94.310845    274.141876      304.985199  304.985199   \n",
       "Greece         5.468647   3.741706      9.404870       10.512584   10.512584   \n",
       "Iraq          25.160052  47.411283     23.626308       51.411167   23.626308   \n",
       "Netherlands   69.682458  69.624098    126.926270      149.290207  142.147995   \n",
       "\n",
       "             nocontrol_control  \n",
       "Australia             0.094513  \n",
       "France                0.112509  \n",
       "Greece                0.117781  \n",
       "Iraq                  1.176014  \n",
       "Netherlands           0.176196  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the name of target countries\n",
    "# target_cols=['Albania','Algeria','Argentina','Armenia','Australia','Azerbaijan','Bangladesh','Belarus','Belgium','Bermuda',\n",
    "#              'Bolivia','Brazil','Bulgaria','Canada','Chile','Colombia','Costa Rica','Cuba','Czech Republic','Denmark',\n",
    "#              'El Salvador','Estonia','Finland','France','Ghana','Gibraltar','Greece','Honduras','Hungary','India',\n",
    "#              'Indonesia','Iran','Iraq','Ireland','Israel','Jamaica','Jordan','Liberia','Luxembourg','Malaysia','Mexico',\n",
    "#              'Morocco','Nepal','Netherlands','Nigeria','Pakistan','Paraguay','Peru','Philippines','Poland','Portugal',\n",
    "#              'Qatar','Republic of the Congo','Romania','Russia','Rwanda','Saudi Arabia','Senegal','Sierra Leone',\n",
    "#              'Singapore','Slovakia','Slovenia','South Africa','Sri Lanka','Switzerland','Thailand','Tunisia','Turkey',\n",
    "#              'Ukraine','United Kingdom','United States','Venezuela']\n",
    "\n",
    "target_cols=['Australia','France','Greece','Iraq','Netherlands']\n",
    "## parameter configure\n",
    "seq_length=7\n",
    "next_days=7\n",
    "\n",
    "INPUT_DIM = 2\n",
    "TIME_STEPS = 7\n",
    "\n",
    "\n",
    "pred_total=[]\n",
    "pre14_true=[]\n",
    "pre7_true=[]\n",
    "\n",
    "pred_control_total=[]\n",
    "pred_nocontrol_total=[]\n",
    "pred_true_total=[]\n",
    "\n",
    "\n",
    "for i in range(len(target_cols)):\n",
    "    print(i,target_cols[i])\n",
    "    \n",
    "    # load the data \n",
    "    country_name='./data/target/'+target_cols[i]+'.xlsx'\n",
    "    data_dist =  pd.read_excel(country_name,encoding='gbk').dropna()\n",
    "    data_dist=data_dist.drop(['截止时间'],axis=1)\n",
    "    data_diff= data_dist['confirmed cases per million'].diff().dropna()\n",
    "    data_diff=pd.concat([data_diff,data_dist.iloc[1:,1]],axis=1)\n",
    "    data_diff=np.array(data_diff)\n",
    "    \n",
    "    x,y,c=create_sequences(data_diff, seq_length, next_days)\n",
    "    c=np.ones((c.shape[0],c.shape[1]))-c.reshape(-1,seq_length)\n",
    "    \n",
    "    \n",
    "    pre14_true.append(y[-8,0])\n",
    "    pre7_true.append(y[-1,0])\n",
    "    \n",
    "    #normalization\n",
    "    x_max=x.max()\n",
    "    x_min=x.min()\n",
    "    x=(x-x_min)/(x_max-x_min)\n",
    "    \n",
    "    y_max=y.max()\n",
    "    y_min=y.min()\n",
    "    y=(y-y_min)/(y_max-y_min)   \n",
    "    \n",
    "    #reshape the dimension\n",
    "    x_train=x.reshape(-1,seq_length,1)\n",
    "    c_train=c.reshape(-1,seq_length)\n",
    "    y_train=y.reshape(-1,1)\n",
    "    \n",
    "    # load the pre-train model and fine-tune the model\n",
    "    source_model='./model/source_model_ALerT-COVID.pkl'  \n",
    "    pre_model= load_model(source_model) \n",
    "    for layer in pre_model.layers[:len(pre_model.layers)-2]:\n",
    "        layer.trainable = False    \n",
    "    pre_model.compile(loss='mse', optimizer=Adam(lr=1e-3))   \n",
    "    pre_model.fit([x_train,c_train], y_train,epochs=10, batch_size=2,verbose = 0)\n",
    " \n",
    "    x_test=data_diff[-7:,0].reshape(1,7,1)   \n",
    "    x_test=(x_test-x_min)/(x_max-x_min)\n",
    "    \n",
    "    #simulation about keeping the lockdown measures or lifting the dockdown measures  \n",
    "    c_test1=np.zeros((1,7))\n",
    "    c_test2=np.ones((1,7))        \n",
    "    c_test3=c_train[-1,:].reshape(1,7)                    \n",
    "        \n",
    "    pred_test1 = pre_model.predict([x_test, c_test1])\n",
    "    pred_test2 = pre_model.predict([x_test, c_test2])\n",
    "    pred_test3 = pre_model.predict([x_test, c_test3])\n",
    "    \n",
    "    pred_test1=np.array(pred_test1)*(y_max-y_min)+y_min    \n",
    "    pred_test2=np.array(pred_test2)*(y_max-y_min)+y_min \n",
    "    pred_test3=np.array(pred_test3)*(y_max-y_min)+y_min \n",
    "    \n",
    "    pred_control_total.append(pred_test1[0,0])\n",
    "    pred_nocontrol_total.append(pred_test2[0,0]) \n",
    "    pred_true_total.append(pred_test3[0,0]) \n",
    "    \n",
    "# save result    \n",
    "result                      = pd.DataFrame(pre14_true,index=target_cols,columns=['pre14_data'])\n",
    "result['pre7_data']         = pre7_true\n",
    "result['pred_control']      = pred_control_total\n",
    "result['pred_nocontrol']    = pred_nocontrol_total\n",
    "result['pred_true']         = pred_true_total\n",
    "result['nocontrol_control'] = (result['pred_nocontrol']-result['pred_control'])/result['pred_control']\n",
    "# result.to_excel('result_predict.xls')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T09:23:01.301137Z",
     "start_time": "2020-06-23T09:23:01.287328Z"
    }
   },
   "outputs": [],
   "source": [
    "result.to_excel('result_predict.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
